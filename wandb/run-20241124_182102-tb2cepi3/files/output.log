model.safetensors: 100%|█████████████████████████████████████████████████████████████████████████████████| 346M/346M [00:24<00:00, 14.0MB/s]
Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.
  0%|                                                                                                              | 0/3125 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/bscho/works/multi-tta/main.py", line 34, in <module>
    main()
  File "/home/bscho/works/multi-tta/main.py", line 24, in main
    trainer.train()
  File "/home/bscho/works/multi-tta/trainers/base_trainer.py", line 48, in train
    model = self.train_step(model, dataloader, optimizer)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/works/multi-tta/trainers/test_trainer.py", line 35, in train_step
    pred, uncertainty = self.mc_dropout(model, samples)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/works/multi-tta/trainers/test_trainer.py", line 99, in mc_dropout
    pred = model(samples)
           ^^^^^^^^^^^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/works/multi-tta/models/baseline.py", line 64, in forward
    samples = self.image_processor(samples)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/site-packages/transformers/image_processing_utils.py", line 41, in __call__
    return self.preprocess(images, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/site-packages/transformers/utils/generic.py", line 852, in wrapper
    return func(*args, **valid_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/site-packages/transformers/models/vit/image_processing_vit.py", line 251, in preprocess
    self.resize(image=image, size=size_dict, resample=resample, input_data_format=input_data_format)
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/site-packages/transformers/models/vit/image_processing_vit.py", line 138, in resize
    return resize(
           ^^^^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/site-packages/transformers/image_transforms.py", line 337, in resize
    do_rescale = _rescale_for_pil_conversion(image)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/site-packages/transformers/image_transforms.py", line 158, in _rescale_for_pil_conversion
    raise ValueError(
ValueError: The image to be converted to a PIL image contains values outside the range [0, 1], got [-2.1179039478302, 2.640000104904175] which cannot be converted to uint8.
