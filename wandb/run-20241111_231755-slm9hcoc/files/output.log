  0%|                                                                                                                                                                                                                                                             | 0/118 [00:14<?, ?it/s]
> /home/bscho/works/multi-tta/models/baseline.py(68)forward()
-> return pred
> /home/bscho/works/multi-tta/models/baseline.py(68)forward()
-> return pred
> /home/bscho/works/multi-tta/models/baseline.py(68)forward()
-> return pred
> /home/bscho/works/multi-tta/models/baseline.py(68)forward()
-> return pred
Traceback (most recent call last):
  File "/home/bscho/works/multi-tta/main.py", line 34, in <module>
    main()
  File "/home/bscho/works/multi-tta/main.py", line 24, in main
    trainer.train()
  File "/home/bscho/works/multi-tta/trainers/base_trainer.py", line 48, in train
    model = self.train_step(model, dataloader, optimizer)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/works/multi-tta/trainers/tent_trainer.py", line 30, in train_step
    pred = model(samples)
           ^^^^^^^^^^^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py", line 193, in forward
    outputs = self.parallel_apply(replicas, inputs, module_kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py", line 212, in parallel_apply
    return parallel_apply(
           ^^^^^^^^^^^^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py", line 118, in parallel_apply
    thread.join()
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/threading.py", line 1149, in join
    self._wait_for_tstate_lock()
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/threading.py", line 1169, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
Exception ignored in: <module 'threading' from '/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/threading.py'>
Traceback (most recent call last):
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/threading.py", line 1624, in _shutdown
    lock.acquire()
KeyboardInterrupt:
