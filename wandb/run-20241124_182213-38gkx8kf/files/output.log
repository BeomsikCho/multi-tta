Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.
  0%|                                                                                                              | 0/3125 [00:00<?, ?it/s]
> /home/bscho/works/multi-tta/models/baseline.py(68)forward()
-> pred['logits'] = self.model(samples)
BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 6.3491e-02, -1.0179e-01,  1.8856e-01,  ..., -3.1934e-01,
           4.7165e-04,  8.4811e-02],
         [ 7.9426e-02, -6.8983e-02,  2.0740e-01,  ..., -2.2682e-01,
           2.5101e-01,  3.0988e-01],
         [ 5.7057e-02, -9.9310e-02,  1.2414e-01,  ..., -1.5329e-01,
           3.0257e-01,  1.4369e-01],
         ...,
         [ 1.8942e-01, -1.8521e-02,  2.6031e-02,  ..., -1.4682e-01,
           2.3692e-01,  7.9293e-02],
         [ 1.8238e-01, -1.3685e-01,  1.3828e-02,  ..., -1.4851e-01,
           3.6352e-01,  7.0866e-02],
         [ 1.8898e-01, -3.4743e-01,  1.1758e-01,  ..., -1.9193e-01,
           2.1788e-01,  1.2339e-01]],

        [[ 1.7251e-01,  2.3135e-01,  1.4318e-01,  ...,  2.5410e-03,
          -3.4212e-01, -1.4362e-01],
         [ 3.1546e-01,  7.1193e-02,  1.4650e-01,  ...,  1.2711e-01,
          -1.6094e-01,  1.3365e-01],
         [ 8.1175e-03,  3.0223e-01,  1.1524e-01,  ...,  6.8024e-02,
           1.1330e-01,  1.9782e-01],
         ...,
         [ 1.8279e-01,  1.5650e-01,  1.1047e-01,  ...,  8.2014e-02,
          -4.6108e-02,  3.9969e-02],
         [ 2.3054e-01,  2.5024e-01,  1.7170e-01,  ..., -9.4505e-02,
           8.2906e-02, -8.5287e-02],
         [ 2.5104e-01, -2.6239e-02,  2.6688e-01,  ...,  1.6496e-01,
          -1.5938e-01,  7.7554e-02]],

        [[ 5.8049e-01, -2.1505e-01, -2.2538e-03,  ..., -2.0675e-03,
           5.4239e-02,  1.6346e-01],
         [ 4.8695e-01, -1.7639e-01,  1.0778e-01,  ..., -1.2604e-01,
          -1.7750e-03,  1.4057e-01],
         [ 4.6298e-01, -1.9245e-01,  3.5607e-02,  ..., -9.8190e-02,
          -2.3826e-02,  2.3430e-01],
         ...,
         [ 3.6318e-02, -3.8737e-02, -9.6935e-04,  ...,  2.0329e-03,
          -2.0112e-02, -2.3219e-02],
         [ 4.4351e-01, -3.9569e-01,  7.4883e-03,  ...,  5.8266e-02,
           4.2210e-03,  1.4081e-01],
         [ 5.9177e-01, -2.5802e-01,  8.3267e-02,  ..., -1.1271e-01,
           2.0124e-02,  1.9538e-01]],

        ...,

        [[ 9.9435e-02, -2.4334e-02,  3.4110e-01,  ..., -4.7367e-02,
          -3.0939e-01, -1.1071e-01],
         [ 7.7998e-02,  1.1971e-01,  1.2432e-01,  ...,  9.5816e-02,
          -1.0585e-01,  7.5181e-03],
         [-3.2110e-02,  9.4637e-04,  5.0221e-02,  ...,  1.0880e-01,
          -1.5708e-01, -1.3071e-02],
         ...,
         [-3.7869e-02, -7.4078e-03,  3.2962e-01,  ...,  3.5822e-01,
          -3.6322e-01,  1.2042e-02],
         [ 1.9045e-01,  1.4497e-01,  2.0473e-01,  ...,  1.1050e-02,
          -3.1840e-01,  1.2515e-03],
         [ 3.6072e-02, -8.2750e-02,  2.2650e-01,  ...,  8.6024e-02,
          -1.2190e-01,  1.5982e-01]],

        [[ 1.3286e-02,  2.5874e-01, -1.2131e-01,  ..., -1.7968e-01,
          -3.6216e-01, -9.0255e-02],
         [-2.6765e-01,  1.4972e-01, -1.2343e-01,  ..., -1.2290e-01,
          -1.4769e-01, -1.7566e-01],
         [-5.8336e-02,  2.0396e-01, -3.4726e-01,  ..., -1.3641e-01,
          -3.4650e-02, -1.7252e-01],
         ...,
         [ 2.0102e-01,  2.2782e-01, -5.2389e-03,  ..., -9.0498e-02,
          -1.0245e-01, -8.8632e-02],
         [-1.7588e-01,  4.1863e-01, -1.8573e-01,  ..., -1.1510e-01,
          -2.2350e-01, -1.0367e-01],
         [ 2.8262e-02,  2.7776e-01, -2.2875e-01,  ..., -1.9221e-01,
          -4.8855e-02, -1.7498e-01]],

        [[ 1.0668e-01, -2.2096e-02,  1.0353e-01,  ..., -1.8993e-01,
          -3.9063e-02, -2.1582e-01],
         [ 1.7476e-01,  4.1668e-02,  5.7336e-02,  ..., -2.1257e-01,
           5.9989e-02,  2.6193e-02],
         [ 6.8030e-02, -2.3657e-01,  1.7791e-01,  ..., -1.0366e-01,
           1.5659e-01,  2.9548e-01],
         ...,
         [-7.2470e-03, -4.4503e-02,  1.2319e-02,  ..., -1.8852e-02,
           2.9206e-02, -2.9411e-02],
         [ 1.1978e-01, -3.9913e-01,  7.5042e-02,  ..., -2.6063e-02,
           5.8861e-02, -1.9454e-01],
         [ 2.4179e-01, -2.6127e-01,  1.4132e-02,  ..., -5.8396e-02,
           1.4073e-01, -8.0396e-03]]], device='cuda:0',
       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.1551,  0.0323, -0.1713,  ...,  0.5968,  0.6661, -0.6865],
        [-0.2217,  0.2349, -0.0868,  ...,  0.4539,  0.0981, -0.1511],
        [-0.0582,  0.6162, -0.5153,  ...,  0.6772,  0.5325, -0.8188],
        ...,
        [-0.2158,  0.1175, -0.7580,  ...,  0.7838,  0.0405, -0.0026],
        [-0.0748,  0.1668,  0.1223,  ...,  0.5171,  0.7175, -0.3038],
        [ 0.4942,  0.4198, -0.0676,  ...,  0.5038,  0.7316, -0.7479]],
       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, attentions=None)
*** AttributeError: 'BaseModelOutputWithPooling' object has no attribute 'shape'
odict_keys(['last_hidden_state', 'pooler_output'])
tensor([[ 0.1551,  0.0323, -0.1713,  ...,  0.5968,  0.6661, -0.6865],
        [-0.2217,  0.2349, -0.0868,  ...,  0.4539,  0.0981, -0.1511],
        [-0.0582,  0.6162, -0.5153,  ...,  0.6772,  0.5325, -0.8188],
        ...,
        [-0.2158,  0.1175, -0.7580,  ...,  0.7838,  0.0405, -0.0026],
        [-0.0748,  0.1668,  0.1223,  ...,  0.5171,  0.7175, -0.3038],
        [ 0.4942,  0.4198, -0.0676,  ...,  0.5038,  0.7316, -0.7479]],
       device='cuda:0', grad_fn=<TanhBackward0>)
torch.Size([16, 768])
torch.Size([16, 197, 768])
Traceback (most recent call last):
  File "/home/bscho/works/multi-tta/main.py", line 34, in <module>
    main()
  File "/home/bscho/works/multi-tta/main.py", line 24, in main
    trainer.train()
  File "/home/bscho/works/multi-tta/trainers/base_trainer.py", line 48, in train
    model = self.train_step(model, dataloader, optimizer)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/works/multi-tta/trainers/test_trainer.py", line 35, in train_step
    pred, uncertainty = self.mc_dropout(model, samples)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/works/multi-tta/trainers/test_trainer.py", line 99, in mc_dropout
    pred = model(samples)
           ^^^^^^^^^^^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/works/multi-tta/models/baseline.py", line 68, in forward
    pred['logits'] = self.model(samples)
                     ^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
