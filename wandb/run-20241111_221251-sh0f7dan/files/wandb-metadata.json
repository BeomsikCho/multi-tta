{
  "os": "Linux-5.4.0-196-generic-x86_64-with-glibc2.31",
  "python": "3.12.7",
  "startedAt": "2024-11-11T13:12:51.361404Z",
  "args": [
    "--config",
    "config/tent.yaml",
    "--mode",
    "train",
    "--device",
    "cuda:0,1,2,3,4,5"
  ],
  "program": "/home/bscho/works/multi-tta/main.py",
  "codePath": "main.py",
  "git": {
    "remote": "git@github.com:BeomsikCho/multi-tta.git",
    "commit": "2589e9146d79dab5bf2c904903e4dc5086d83c62"
  },
  "email": "whqjatlr369@gmail.com",
  "root": "/home/bscho/works/multi-tta",
  "host": "gpu2",
  "username": "bscho",
  "executable": "/home/bscho/anaconda3/envs/multiTTA/bin/python3",
  "codePathLocal": "main.py",
  "cpu_count": 128,
  "cpu_count_logical": 256,
  "gpu": "NVIDIA GeForce RTX 3090",
  "gpu_count": 7,
  "disk": {
    "/": {
      "total": "906790924288",
      "used": "569258508288"
    }
  },
  "memory": {
    "total": "270317309952"
  },
  "cpu": {
    "count": 128,
    "countLogical": 256
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere"
    }
  ],
  "cudaVersion": "11.8"
}