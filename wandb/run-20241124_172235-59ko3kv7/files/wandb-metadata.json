{
  "os": "Linux-5.4.0-200-generic-x86_64-with-glibc2.31",
  "python": "3.12.7",
  "startedAt": "2024-11-24T08:22:35.085164Z",
  "args": [
    "--mode",
    "train",
    "--config",
    "config/test_vit.yaml",
    "--device",
    "cuda:0,1,2,3"
  ],
  "program": "/home/bscho/works/multi-tta/main.py",
  "codePath": "main.py",
  "git": {
    "remote": "git@github.com:BeomsikCho/multi-tta.git",
    "commit": "2aab0f69e2650a79fc660805036f2aba6b80957e"
  },
  "email": "whqjatlr369@gmail.com",
  "root": "/home/bscho/works/multi-tta",
  "host": "gpu2",
  "username": "bscho",
  "executable": "/home/bscho/anaconda3/envs/multiTTA/bin/python3",
  "codePathLocal": "main.py",
  "cpu_count": 128,
  "cpu_count_logical": 256,
  "gpu": "NVIDIA GeForce RTX 3090",
  "gpu_count": 7,
  "disk": {
    "/": {
      "total": "906790924288",
      "used": "570509029376"
    }
  },
  "memory": {
    "total": "270317322240"
  },
  "cpu": {
    "count": 128,
    "countLogical": 256
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere"
    },
    {
      "name": "NVIDIA GeForce RTX 3090",
      "memoryTotal": "25769803776",
      "cudaCores": 10496,
      "architecture": "Ampere"
    }
  ],
  "cudaVersion": "11.8"
}