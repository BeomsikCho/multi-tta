  0%|                                                                                                                                                                                                                                                             | 0/118 [00:00<?, ?it/s]
> /home/bscho/works/multi-tta/models/baseline.py(63)forward()
-> pred['logits'] = self.fc(pred['last_hidden_state'])
> /home/bscho/works/multi-tta/models/baseline.py(64)forward()
-> return pred
{'last_hidden_state': tensor([[[ 5.6369e+00, -3.2311e+00, -4.4865e-01,  ...,  1.7768e+00,
          -1.7272e+00, -1.0813e+00],
         [ 5.1022e+00, -2.8200e+00, -1.6513e+00,  ...,  1.7445e+00,
          -1.6357e+00, -1.9369e+00],
         [ 4.9677e+00, -4.7794e+00, -1.0328e-01,  ...,  2.5068e+00,
          -1.7737e+00, -9.8628e-01],
         ...,
         [ 5.3816e+00, -2.6976e+00,  5.0618e-01,  ...,  2.6410e+00,
          -2.1389e+00, -1.0617e+00],
         [ 5.3752e+00, -2.5360e+00,  5.4148e-01,  ...,  2.1819e+00,
          -2.1616e+00, -7.0785e-01],
         [ 5.4933e+00, -2.3352e+00,  9.3700e-01,  ...,  2.0150e+00,
          -2.0044e+00, -1.4585e-01]],

        [[-1.5196e+00,  4.7003e-01, -1.3410e-01,  ..., -2.4706e+00,
           1.8794e-01, -4.9006e-01],
         [-1.3561e+00,  5.0220e-01, -6.4341e-01,  ..., -2.3731e+00,
           1.5719e-01, -4.9973e-01],
         [-1.6712e+00,  7.1600e-01,  9.3727e-02,  ..., -2.0660e+00,
           1.7975e-01, -6.9304e-01],
         ...,
         [-5.3321e-01,  1.2513e+00,  8.8354e-01,  ..., -8.1772e-01,
          -1.8964e+00, -5.5276e-02],
         [-1.1332e+00,  1.0561e+00,  1.0859e+00,  ...,  3.1037e-01,
          -9.7988e-01,  1.3657e+00],
         [ 6.3210e-01,  1.5838e+00,  2.1705e+00,  ...,  8.7232e-02,
          -2.4628e+00, -4.1141e-02]],

        [[-1.3660e-02, -1.4889e-01, -1.2623e+00,  ...,  1.3807e+00,
          -3.3847e-01,  9.1512e-01],
         [ 1.8530e+00,  1.6199e+00, -2.2126e+00,  ..., -3.5130e+00,
           1.6949e+00,  9.1402e-01],
         [ 2.7240e+00,  5.9205e-01, -1.7610e+00,  ..., -2.5366e+00,
          -1.0968e+00, -8.3009e-01],
         ...,
         [ 1.3263e-01,  1.4858e+00,  2.0641e+00,  ...,  5.0521e-01,
          -3.6838e-01,  1.5293e+00],
         [ 4.4916e+00, -9.3695e-01, -4.7398e-01,  ..., -3.3142e+00,
           1.4589e+00,  2.6582e-01],
         [ 2.7185e+00, -1.0969e+00, -1.9637e+00,  ..., -2.4580e+00,
          -1.2457e-03,  4.7002e-01]],

        ...,

        [[ 4.0151e+00, -3.1743e+00, -3.6718e+00,  ..., -1.6528e+00,
           6.7687e-01, -1.3479e+00],
         [ 2.2594e+00, -2.7817e+00, -2.4447e+00,  ..., -1.2765e+00,
           1.2125e+00,  5.9038e-01],
         [ 3.6706e+00, -2.9496e+00, -3.3117e+00,  ..., -3.6046e+00,
          -7.7961e-01, -1.0715e+00],
         ...,
         [ 2.6621e+00, -4.3664e+00, -1.2260e+00,  ..., -1.9766e+00,
           5.7851e-01, -1.2410e+00],
         [ 1.5069e+00, -6.9417e-01, -2.2442e+00,  ...,  3.3282e-02,
           4.5462e-01, -9.1207e-01],
         [ 2.8729e+00, -2.7224e+00, -4.5278e-01,  ..., -3.3101e+00,
          -1.1429e+00, -2.3384e+00]],

        [[ 4.0071e+00, -2.3184e+00,  1.5713e+00,  ...,  2.3020e+00,
           1.6713e-01, -2.6288e+00],
         [ 4.3429e+00, -1.7752e+00,  2.5499e+00,  ...,  2.1168e+00,
          -1.7342e-01, -2.6129e+00],
         [ 6.3089e-01, -6.2571e-01, -1.7626e-01,  ...,  7.5650e-01,
           1.6818e+00, -9.2535e-01],
         ...,
         [ 2.2502e+00, -1.1778e+00, -1.3193e+00,  ...,  3.3283e+00,
           8.1229e-01, -2.8385e-01],
         [ 4.4484e+00, -2.0546e+00,  7.0519e-01,  ...,  2.6497e+00,
          -5.2096e-02, -1.3120e+00],
         [ 1.3123e+00, -1.8200e+00,  1.1902e+00,  ...,  3.5411e+00,
          -2.1228e-01,  1.9645e+00]],

        [[-6.2493e-01,  2.1441e+00,  1.2304e+00,  ...,  5.5217e-01,
          -2.2609e+00,  4.3666e-01],
         [-6.8237e-01,  3.7198e+00,  1.3780e+00,  ..., -1.1665e-02,
          -2.3017e+00,  1.4542e+00],
         [-6.4018e-02,  3.3781e+00,  8.0575e-01,  ...,  1.5809e-01,
          -1.5143e+00,  7.6964e-01],
         ...,
         [-3.1361e+00,  4.2414e+00,  8.1289e-01,  ..., -1.0235e+00,
           2.3655e-01,  1.5147e-01],
         [-8.9343e-01,  5.8563e+00, -2.1883e-01,  ...,  6.7479e-01,
          -5.0807e-01, -1.2527e+00],
         [-3.4399e+00,  3.0586e+00,  9.4678e-01,  ...,  3.0170e+00,
          -8.4274e-01,  1.5062e+00]]], device='cuda:0',
       grad_fn=<NativeLayerNormBackward0>), 'logits': tensor([[[-2.0373, -1.0932, -0.3912,  ...,  0.8514, -1.1081, -1.6836],
         [-1.1542, -1.6992, -0.6898,  ...,  0.2332, -1.9821, -2.1766],
         [-1.6232, -0.9198, -0.2418,  ...,  0.8742, -0.7406, -1.9278],
         ...,
         [-1.0361, -1.6544,  0.1749,  ...,  1.2704, -0.6367, -1.6524],
         [-0.9843, -1.6746,  0.3647,  ...,  1.2577, -0.5333, -1.7964],
         [-1.2026, -1.4883,  0.2714,  ...,  0.9607, -0.5357, -1.9061]],

        [[-0.7563, -3.5356,  1.8183,  ..., -0.4609,  1.8962,  1.0687],
         [-0.6234, -3.3054,  1.7252,  ..., -0.2628,  1.8437,  1.0514],
         [-0.7797, -3.4875,  1.6615,  ..., -0.6304,  1.7567,  1.2186],
         ...,
         [ 2.7781, -0.9125,  0.9754,  ...,  0.2976,  1.6595,  1.7712],
         [ 2.7218, -1.9355,  0.8781,  ...,  0.3574,  1.8036,  1.2932],
         [ 0.9923, -1.0341,  0.7029,  ...,  0.7120,  1.1917,  1.7888]],

        [[ 0.7949, -0.8874, -1.0742,  ...,  1.5146,  2.5253,  0.5088],
         [-0.3505, -1.1093,  0.4321,  ...,  0.5966,  1.2469,  1.1676],
         [ 0.2998, -1.4344,  1.0580,  ...,  0.4881,  1.2631,  0.1702],
         ...,
         [-0.2558,  0.3378, -0.4054,  ...,  0.5779,  1.6157,  0.8439],
         [ 0.1354, -0.1647,  0.8797,  ...,  1.3951,  1.9976,  0.8003],
         [ 0.4868, -0.5753, -0.0599,  ...,  0.3050,  1.3926, -0.0153]],

        ...,

        [[-2.4697, -1.7917,  0.4191,  ...,  0.5389, -0.4417, -1.6040],
         [-1.8335, -1.8237,  0.2390,  ...,  0.9749, -0.1356, -1.5428],
         [-2.9973, -1.6166,  0.6113,  ...,  0.3329, -1.3511, -1.6294],
         ...,
         [-2.2178, -1.8161,  0.5889,  ...,  0.5411, -0.8673, -1.4907],
         [-1.5757, -1.7146,  0.6628,  ..., -0.9784, -1.8572, -0.0633],
         [-1.8628, -1.4983,  1.0535,  ...,  0.4085, -1.0449, -0.3160]],

        [[-1.3686, -1.2600, -0.1874,  ...,  0.0987,  1.3611, -0.2306],
         [-1.1375, -0.9036, -0.2278,  ..., -0.0190,  1.3450, -0.4264],
         [ 0.0212, -1.3071, -1.4588,  ...,  0.6279,  1.9987, -1.1977],
         ...,
         [-0.3968, -1.0302, -1.5220,  ...,  1.5965,  0.7881, -0.4141],
         [-1.2385, -1.6067, -0.5459,  ..., -0.3127,  1.5681,  0.0122],
         [ 0.1849, -1.8064, -1.2597,  ...,  0.5305,  2.3568, -0.3687]],

        [[-0.5325, -0.0600,  0.1793,  ..., -2.3377, -0.7011,  1.3023],
         [-0.4761, -0.0897,  0.0619,  ..., -1.9937, -0.6449,  1.0646],
         [-0.7387, -0.3868, -0.1066,  ..., -1.9235, -0.8839,  1.2215],
         ...,
         [-0.0391,  1.1220,  0.4691,  ..., -1.3337, -0.5231,  1.3586],
         [-0.8885, -0.6907,  0.9788,  ..., -2.2568, -0.2459,  0.7959],
         [-0.5401, -0.7861,  1.2805,  ..., -2.1906, -0.0157,  0.5327]]],
       device='cuda:0', grad_fn=<ViewBackward0>)}
Traceback (most recent call last):
  File "/home/bscho/works/multi-tta/main.py", line 34, in <module>
    main()
  File "/home/bscho/works/multi-tta/main.py", line 24, in main
    trainer.train()
  File "/home/bscho/works/multi-tta/trainers/base_trainer.py", line 48, in train
    model = self.train_step(model, dataloader, optimizer)
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/works/multi-tta/trainers/tent_trainer.py", line 30, in train_step
    pred = model(samples)
           ^^^^^^^^^^^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/works/multi-tta/models/baseline.py", line 64, in forward
    return pred
           ^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/bscho/anaconda3/envs/multiTTA/lib/python3.12/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
